{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tt8XTjvmsE6j"
      },
      "source": [
        "### REQURIED LIB\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UDyeOU_MsE6m"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision\n",
        "from torchvision.datasets import MNIST\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if CUDA (GPU) is available, otherwise use CPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "1DHA_US_Zgez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "id": "XRI6ETCS71KP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing and Loading Dataset"
      ],
      "metadata": {
        "id": "6ymx4W7Q7ske"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# transformations for the images\n",
        "transform = transforms.ToTensor()\n",
        "\n",
        "# Load the MNIST dataset and create data loaders\n",
        "train_dataset = MNIST(root='./data', train=True, transform=transform, download=True)\n",
        "test_dataset = MNIST(root='./data', train=False, transform=transform, download=True)\n",
        "\n",
        "train_dataloader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
        "test_dataloader = DataLoader(dataset=test_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "CHKRnxwEZm2U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset"
      ],
      "metadata": {
        "id": "JUtA755ncPg_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualizing the Data\n",
        "Let's visualize a few examples from the dataset to understand the input images better."
      ],
      "metadata": {
        "id": "cwU0dCWv4Wnk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Function to display a grid of images\n",
        "def show_images(images, labels, nrows, ncols):\n",
        "    fig, axes = plt.subplots(nrows, ncols, figsize=(10, 6))\n",
        "    for i, ax in enumerate(axes.flat):\n",
        "        ax.imshow(np.squeeze(images[i]), cmap='gray')\n",
        "        ax.set_title(f\"Label: {labels[i]}\")\n",
        "        ax.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Get a batch of images and labels from the test dataset\n",
        "images, labels = next(iter(test_dataloader))\n",
        "\n",
        "# Display the images and their labels\n",
        "show_images(images, labels, 4, 8)"
      ],
      "metadata": {
        "id": "Eg4-yFP7axtP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img , label = train_dataset[0]\n",
        "plt.imshow(np.squeeze(img), cmap='gray')"
      ],
      "metadata": {
        "id": "IUQ1ZSj2bGjV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wtel1hdLsE6q"
      },
      "source": [
        "## Model Architecture\n",
        "Next, we'll define our CNN model architecture using PyTorch.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nfaMQIIrsE6q"
      },
      "outputs": [],
      "source": [
        "\n",
        "class DigitClassification(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5)\n",
        "        self.pool = nn.MaxPool2d(2)\n",
        "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=8, kernel_size=3)\n",
        "        self.L1 = nn.Linear(in_features=8*5*5, out_features=64)\n",
        "        self.L2 = nn.Linear(in_features=64, out_features=10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)  # 1*28*28 --> 16*24*24\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        x = x.flatten(start_dim=1, end_dim=-1)\n",
        "        x = F.relu(self.L1(x))\n",
        "        x = F.relu(self.L2(x))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2C-xqwrsE6r"
      },
      "source": [
        "#Training the Model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Loss Function and Optimizer\n",
        "We need to specify the loss function and optimizer for training the model."
      ],
      "metadata": {
        "id": "Wki5r4h_5Be4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I-hY5K28sE6r"
      },
      "outputs": [],
      "source": [
        "# Instantiate the model and move it to the appropriate device\n",
        "model = DigitClassification().to(device)\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Loop\n",
        "Now, we'll implement the training loop to train our model on the MNIST dataset."
      ],
      "metadata": {
        "id": "R4Mu6J0s5JZv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dqXAMPyAsE6r"
      },
      "outputs": [],
      "source": [
        "# Define the training function\n",
        "def train(model, train_dataloader, criterion, optimizer):\n",
        "    total_loss = 0\n",
        "    for batch in train_dataloader:\n",
        "        data, label = batch[0].to(device), batch[1].to(device)  # Move data to device\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        predicted = model(data)\n",
        "        loss = criterion(predicted, label)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    return total_loss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUC-JfRzsE6r"
      },
      "source": [
        "### TEST loop\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pwb_dWeLsE6s"
      },
      "outputs": [],
      "source": [
        "def test(model, test_dataloader, criterion, optimizer):\n",
        "    total_loss = 0\n",
        "    with torch.no_grad():  # No need to track gradients during testing\n",
        "        for batch in test_dataloader:\n",
        "            data, label = batch[0].to(device), batch[1].to(device)  # Move data to device\n",
        "\n",
        "            predicted = model(data)\n",
        "            loss = criterion(predicted, label)\n",
        "\n",
        "            total_loss += loss.item()\n",
        "    return total_loss"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and test the model for a certain number of epochs\n",
        "num_epochs = 10\n",
        "training_losses = []\n",
        "testing_losses = []"
      ],
      "metadata": {
        "id": "gJdk4tRwahQZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qOjCJ3ZhsE6s"
      },
      "outputs": [],
      "source": [
        "for epoch in tqdm(range(num_epochs), desc='Training Progress'):\n",
        "\n",
        "    training_loss = train(model, train_dataloader, criterion, optimizer)\n",
        "    testing_loss = test(model, test_dataloader, criterion, optimizer)\n",
        "\n",
        "    # Append losses for visualization\n",
        "    training_losses.append(training_loss)\n",
        "    testing_losses.append(testing_loss)\n",
        "\n",
        "    print(f\"Training Loss: {training_loss}, Testing Loss: {testing_loss}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting training and testing losses\n",
        "plt.plot(training_losses, label='Training Loss')\n",
        "plt.plot(testing_losses, label='Testing Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Testing Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "j44TIgylanGl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predictions and Visualization\n",
        "## Making Predictions\n",
        "Let's make predictions on new data using the trained model."
      ],
      "metadata": {
        "id": "QUHwHllj56eX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to make predictions on new data\n",
        "def predict(model, dataloader):\n",
        "    predictions = []\n",
        "    with torch.no_grad():\n",
        "        for data in dataloader:\n",
        "            inputs = data[0].to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            predictions.extend(predicted.cpu().numpy())\n",
        "    return predictions\n"
      ],
      "metadata": {
        "id": "Anm0iy46v0BX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the test dataset\n",
        "test_predictions = predict(model, test_dataloader)"
      ],
      "metadata": {
        "id": "jHwac8mOet2A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualizing Predictions\n",
        "We'll visualize a random sample of test images along with their predicted labels."
      ],
      "metadata": {
        "id": "xkXSgzl96Fnw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to plot a random sample of images along with their predicted labels\n",
        "def visualize_predictions(dataset, predictions, num_samples=5):\n",
        "    plt.figure(figsize=(15, 7))\n",
        "    samples = np.random.choice(len(dataset), num_samples, replace=False)\n",
        "    for i, idx in enumerate(samples):\n",
        "        plt.subplot(1, num_samples, i + 1)\n",
        "        image, label = dataset[idx]\n",
        "        plt.imshow(image.squeeze(), cmap='gray')\n",
        "        plt.title(f\"Predicted: {predictions[idx]}, Actual: {label}\")\n",
        "        plt.axis('off')\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "TEn-_zDaezIO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize predictions on a random sample of test images\n",
        "visualize_predictions(test_dataset, test_predictions)"
      ],
      "metadata": {
        "id": "2qW9KUQUe11S"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "cell_execution_strategy": "setup"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}